{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnN0Al5T7SryapPizssHtq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4sGeViuvxSYw","outputId":"d9077495-cf7e-45eb-941c-3a5721282d4e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715911437668,"user_tz":300,"elapsed":21702,"user":{"displayName":"Yeison Micolta","userId":"09436347256461458623"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"]}],"source":["!pip install tabulate\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8pMoMCfvxSYz","outputId":"7d0f4ae3-b2f3-4f37-c5c4-10e166636165","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715911444496,"user_tz":300,"elapsed":6832,"user":{"displayName":"Yeison Micolta","userId":"09436347256461458623"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------+-----------------------------------------------------------+\n","| Comentario Original                                      | Comentario Lematizado                                     |\n","+==========================================================+===========================================================+\n","| Los zapatos son muy cómodos y bonitos.                   | Los zapatos son muy cómodos y bonito .                    |\n","+----------------------------------------------------------+-----------------------------------------------------------+\n","| La calidad de la tela de la camisa es excelente.         | La calidad de la tela de la camisa e excelente .          |\n","+----------------------------------------------------------+-----------------------------------------------------------+\n","| No estoy satisfecho con el tamaño del bolso.             | No estoy satisfecho con el tamaño del bolso .             |\n","+----------------------------------------------------------+-----------------------------------------------------------+\n","| Los productos de esta tienda son geniales.               | Los productos de esta tienda son geniales .               |\n","+----------------------------------------------------------+-----------------------------------------------------------+\n","| El color de la blusa no coincide con la imagen en línea. | El color de la blusa no coincide con la imagen en línea . |\n","+----------------------------------------------------------+-----------------------------------------------------------+\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from tabulate import tabulate\n","\n","# Descargar recursos necesarios de NLTK\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# Conjunto de comentarios de los clientes\n","comentarios = [\n","    \"Los zapatos son muy cómodos y bonitos.\",\n","    \"La calidad de la tela de la camisa es excelente.\",\n","    \"No estoy satisfecho con el tamaño del bolso.\",\n","    \"Los productos de esta tienda son geniales.\",\n","    \"El color de la blusa no coincide con la imagen en línea.\"\n","]\n","\n","# Inicializar el lematizador de palabras\n","lemmatizador = WordNetLemmatizer()\n","\n","# Tokenizar cada comentario y lematizar las palabras\n","tabla_datos = []\n","for comentario in comentarios:\n","    tokens = word_tokenize(comentario)\n","    lematizados = [lemmatizador.lemmatize(token) for token in tokens]\n","    tabla_datos.append([comentario, \" \".join(lematizados)])\n","\n","# Imprimir tabla con comentarios originales y lematizados\n","print(tabulate(tabla_datos, headers=['Comentario Original', 'Comentario Lematizado'], tablefmt='grid'))\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"rgKDLdZYxSY0","outputId":"7568dbb5-b10e-4283-df71-8189a048f886","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715911445117,"user_tz":300,"elapsed":625,"user":{"displayName":"Yeison Micolta","userId":"09436347256461458623"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["                                           review_en  \\\n","0  One of the other reviewers has mentioned that ...   \n","1  A wonderful little production. The filming tec...   \n","2  I thought this was a wonderful way to spend ti...   \n","\n","                                   lemmatized_review  \n","0  One of the other reviewer ha mentioned that af...  \n","1  A wonderful little production . The filming te...  \n","2  I thought this wa a wonderful way to spend tim...  \n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import pandas as pd\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","# Descargar recursos necesarios de NLTK\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# Crear un DataFrame con los datos de las reseñas\n","data = {\n","    'review_en': [\n","        \"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked...\",\n","        \"A wonderful little production. The filming technique is very unassuming...\",\n","        \"I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater...\"\n","        # Agrega más reseñas aquí si es necesario\n","    ]\n","}\n","df = pd.DataFrame(data)\n","\n","# Inicializar el lematizador de palabras\n","lemmatizer = WordNetLemmatizer()\n","\n","# Función para lematizar texto\n","def lemmatize_text(text):\n","    tokens = word_tokenize(text)\n","    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","    return ' '.join(lemmatized_tokens)\n","\n","# Aplicar lematización a la columna de reseñas\n","df['lemmatized_review'] = df['review_en'].apply(lemmatize_text)\n","\n","# Mostrar las primeras filas del DataFrame con las reseñas lematizadas\n","print(df[['review_en', 'lemmatized_review']].head())\n"]}]}